{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-docs-1",
   "metadata": {},
   "source": [
    "# Basic demonstration of Dspy integration functionality with the Unity Catalog AI Toolkit SDK\n",
    "\n",
    "To get started with this, you will need an OpenAI API Key. \n",
    "\n",
    "Once you have acquired your key, set it to the environment variable `OPENAI_API_KEY` after storing it in the `Databricks Secrets` API (accessible via dbutils or the databricks sdk workspace client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa44a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uqqq unitycatalog-dspy[databricks] dspy mlflow\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9500c9",
   "metadata": {},
   "source": [
    "## Setting your API Key\n",
    "\n",
    "Don't forget to remove the key after you're done running cell 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "secret_scope = \"puneet_jain\"  # Change me!\n",
    "\n",
    "# Run this if you don't have the API key set to your secrets scope yet\n",
    "\n",
    "# if secret_scope not in [scope.name for scope in workspace_client.secrets.list_scopes()]:\n",
    "#     workspace_client.secrets.create_scope(secret_scope)\n",
    "\n",
    "# my_secret = \"<your API key, temporarily>\"\n",
    "\n",
    "# workspace_client.secrets.put_secret(scope=secret_scope, key=\"openai_api_key\", string_value=my_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-key-note-1",
   "metadata": {},
   "source": [
    "## Fetch the key and set it to the environment variable key that the OpenAI SDK needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b6d45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = base64.b64decode(\n",
    "    workspace_client.secrets.get_secret(scope=secret_scope, key=\"openai_api_key\").value\n",
    ").decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a674041",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"OPENAI_API_KEY\" in os.environ, (\n",
    "    \"Please set the OPENAI_API_KEY environment variable to your OpenAI API key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2b14356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from unitycatalog.ai.dspy.toolkit import UCFunctionToolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69590e6e",
   "metadata": {},
   "source": [
    "## Import the UC client for Databricks UC. \n",
    "This will allow for function creation through either the `create_function` API (requires the defined `sql_body` statement) or the `create_python_function` (requires a type-hint-applied and docstring commented python callable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97c52c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"mlops_pj\"  # Change me !\n",
    "SCHEMA = \"rr_rag_chatbot\"  # Change me if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fdf5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = DatabricksFunctionClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182f54a",
   "metadata": {},
   "source": [
    "### Define a Callable\n",
    "The requirements for the callable:\n",
    "\n",
    "**typing**\n",
    "\n",
    "Types **must** be supplied for both the arguments and the return type. Function signatures that do not have these defined will raise a `ValueError`.\n",
    "\n",
    "The following types are not allowed:\n",
    "`Union`\n",
    "`Any`\n",
    "\n",
    "Additional caveats:\n",
    "Collections **must** supply typing of the interior components. For instance, ``typing.Dict`` is not allowed, but ``typing.Dict[str, str]`` will work correctly. \n",
    "\n",
    "**doc strings**\n",
    "\n",
    "The doc string **must** be in the Google Docstring format.\n",
    "Args and Returns comments are optional, but the function description **is required**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "043fc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Retrieve mock weather information for a given city.\n",
    "\n",
    "    This function looks up predefined mock weather data for a set of cities.\n",
    "    If the city is not found in the dataset, a default message is returned.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city to retrieve weather data for.\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the weather for the given city, or\n",
    "        \"Weather data not available\" if the city is not in the dataset.\n",
    "\n",
    "    Example:\n",
    "        >>> get_weather(\"New York\")\n",
    "        'Sunny, 25°C'\n",
    "\n",
    "        >>> get_weather(\"Boston\")\n",
    "        'Weather data not available'\n",
    "    \"\"\"\n",
    "    mock_data = {\n",
    "        \"New York\": \"Sunny, 25°C\",\n",
    "        \"Los Angeles\": \"Cloudy, 20°C\",\n",
    "        \"Chicago\": \"Rainy, 15°C\",\n",
    "        \"Houston\": \"Thunderstorms, 30°C\",\n",
    "        \"Phoenix\": \"Sunny, 35°C\",\n",
    "    }\n",
    "    return mock_data.get(city, \"Weather data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e97351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionInfo(browse_only=None, catalog_name='mlops_pj', comment='Retrieve mock weather information for a given city. This function looks up predefined mock weather data for a set of cities. If the city is not found in the dataset, a default message is returned.', created_at=1756333139900, created_by='puneet.jain@databricks.com', data_type=<ColumnTypeName.STRING: 'STRING'>, external_language='Python', external_name=None, full_data_type='STRING', full_name='mlops_pj.rr_rag_chatbot.get_weather', function_id='e1c1b67c-82ff-4ce9-8501-ba194bcce21e', input_params=FunctionParameterInfos(parameters=[FunctionParameterInfo(name='city', type_text='string', type_name=<ColumnTypeName.STRING: 'STRING'>, position=0, comment='The name of the city to retrieve weather data for.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"comment\":\"The name of the city to retrieve weather data for.\"}}', type_precision=0, type_scale=0)]), is_deterministic=False, is_null_call=None, metastore_id='b86c6879-8c55-4e70-a585-18d16a4fa6e9', name='get_weather', owner='puneet.jain@databricks.com', parameter_style=<FunctionInfoParameterStyle.S: 'S'>, properties='{\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.taskWaitTimeInSeconds\":\"1000\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batchSession.terminate.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.purposeBuiltFunctions.translate.instruction\":\"### Instruction\\\\n\\\\nTranslate the provided text to %s, and output only the translated text\\\\nin the target language in this format: <DBSQLAI>translated text</DBSQLAI>.\\\\n\\\\nIf the text is already in the target language, output the provided text.\\\\n\\\\n### Text\\\\n\\\\n%s\",\"isolation.strict\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdTotalQpsIncreaseRatio\":\"0.0\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.useDynamicTaskQueueExecutor\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batchInferenceApi.enabled\":\"true\",\"sqlConfig.spark.sql.stableDerivedColumnAlias.enabled\":\"true\",\"sqlConfig.spark.sql.orc.compression.codec\":\"snappy\",\"sqlConfig.spark.sql.streaming.stateStore.providerClass\":\"com.databricks.sql.streaming.state.RocksDBStateStoreProvider\",\"sqlConfig.spark.sql.insertIntoReplaceUsing.enabled\":\"true\",\"sqlConfig.spark.sql.ansi.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.decimal.dataType.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.extract.tileMetadata.enabled\":\"true\",\"sqlConfig.spark.sql.streaming.statefulOperator.stateRebalancing.enabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.dynamicPoolSizeEnabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.debugLogEnabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.remoteHttpClient.maxConnections\":\"2048\",\"sqlConfig.spark.databricks.docingest.client.v2.enabled\":\"true\",\"sqlConfig.spark.sql.legacy.createHiveTableByDefault\":\"false\",\"sqlConfig.spark.sql.shuffleDependency.skipMigration.enabled\":\"true\",\"sqlConfig.spark.sql.streaming.stopTimeout\":\"15s\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.vectorSearch.retryIntervalMultiplierFactor\":\"2.0\",\"sqlConfig.spark.databricks.sql.functions.aiQuery.openAI.oSeries.model.list\":\"o1-mini,o1,o3-mini,o3,o4-mini,gpt-5,gpt-5-mini,gpt-5-nano\",\"sqlConfig.spark.connect.session.connectML.enabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.vectorSearch.maxRetryInterval\":\"120000\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.remoteHttpClient.timeoutInSeconds\":\"360\",\"sqlConfig.spark.sql.legacy.codingErrorAction\":\"true\",\"sqlConfig.spark.sql.cte.recursion.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdCurrentQpsIncreaseRatio\":\"0.0\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.useDedicatedHttpClient\":\"true\",\"sqlConfig.spark.sql.readSideCharPadding\":\"true\",\"sqlConfig.spark.sql.variable.substitute\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiForecast.enabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.threadKeepAliveTimeInSeconds\":\"600\",\"sqlConfig.spark.databricks.sql.expression.aiFunctions.repartition\":\"0\",\"sqlConfig.spark.sql.sources.default\":\"delta\",\"sqlConfig.spark.sql.hive.convertCTAS\":\"true\",\"sqlConfig.spark.sql.artifact.isolation.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.vectorSearch.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.safe.inference.enabled\":\"true\",\"sqlConfig.spark.sql.scripting.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batch.aiQuery.embedding.request.size\":\"40\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batch.execution.size\":\"2048\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.vectorSearch.initialRetryIntervalMillis\":\"1000\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.embeddingsEndpointName\":\"databricks-gte-large-en\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batchSession.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize\":\"2048\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.clusterSizeBasedGlobalParallelism.scaleFactor\":\"512.0\",\"sqlConfig.spark.databricks.sql.functions.aiGen.endpointName\":\"databricks-meta-llama-3-3-70b-instruct\",\"sqlConfig.spark.sql.sources.commitProtocolClass\":\"com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol\",\"sqlConfig.spark.sql.functions.remoteHttpClient.retryOn400TimeoutError\":\"true\",\"sqlConfig.spark.databricks.sql.functions.vectorSearch.use.indexIdentifierOnly\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.purposeBuiltFunctions.batch.execution.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdSuccessRatio\":\"0.95\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.modelEndpointTypeParsing.enabled\":\"true\",\"sqlConfig.spark.sql.parquet.compression.codec\":\"snappy\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.model.parameters.enabled\":\"true\",\"sqlConfig.spark.sql.collation.enabled\":\"true\"}', return_params=None, routine_body=<FunctionInfoRoutineBody.EXTERNAL: 'EXTERNAL'>, routine_definition='\\n    mock_data = {\\n        \"New York\": \"Sunny, 25°C\",\\n        \"Los Angeles\": \"Cloudy, 20°C\",\\n        \"Chicago\": \"Rainy, 15°C\",\\n        \"Houston\": \"Thunderstorms, 30°C\",\\n        \"Phoenix\": \"Sunny, 35°C\"\\n    }\\n    return mock_data.get(city, \"Weather data not available\")\\n', routine_dependencies=None, schema_name='rr_rag_chatbot', security_type=<FunctionInfoSecurityType.DEFINER: 'DEFINER'>, specific_name='get_weather', sql_data_access=<FunctionInfoSqlDataAccess.NO_SQL: 'NO_SQL'>, sql_path=None, updated_at=1756333139900, updated_by='puneet.jain@databricks.com')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_python_function(func=get_weather, catalog=CATALOG, schema=SCHEMA, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8237dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool instance to use with Dspy\n",
    "\n",
    "toolkit = UCFunctionToolkit(function_names=[f\"{CATALOG}.{SCHEMA}.get_weather\"], client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55b2f4",
   "metadata": {},
   "source": [
    "## Enable tracing in MLflow\n",
    "Auto-enabling tracing allows us to see the calls made by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2bcb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "llm = dspy.LM(model=\"openai/gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "dspy.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ab4a3",
   "metadata": {},
   "source": [
    "### Build a simple ReAct agent\n",
    "We define a DSPy signature (`Agent_tools`) for the agent’s inputs/outputs and compose a ReAct module with `tools=toolkit.tools`. The agent maintains a minimal chat history and can call the UC function when helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66a20a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DSPy signature for the agent's inputs/outputs\n",
    "class Agent_tools(dspy.Signature):\n",
    "    \"\"\"AI assistant Able to use tools\"\"\"\n",
    "\n",
    "    input_query = dspy.InputField()\n",
    "    history = dspy.InputField(desc=\"Chat History\")\n",
    "    output = dspy.OutputField(desc=\"Response to User\")\n",
    "\n",
    "\n",
    "# Create a DSPy module for the agent with  ReAct Framework and Tool Calling\n",
    "class Agent(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.history = []\n",
    "        self.tools_utils = dspy.ReAct(Agent_tools, tools=toolkit.tools)\n",
    "\n",
    "    def __call__(self, input: str):\n",
    "        self.add_memory(input)\n",
    "        str_history = \"\\n\".join(self.history.copy())\n",
    "        result = self.tools_utils(input_query=input, history=str_history).output\n",
    "        self.add_memory(result)\n",
    "        return result\n",
    "\n",
    "    def add_memory(self, memory: str):\n",
    "        self.history.append((\"USER: \" if len(self.history) % 2 == 0 else \"AI: \") + memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84d9c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  The current weather in New York is Sunny with a temperature of 25°C. In Chicago, it is Rainy with a temperature of 15°C.\n"
     ]
    }
   ],
   "source": [
    "chat_module = Agent()\n",
    "human_input = \"what is the weather in new york and chicago?\"\n",
    "print(\"AI: \", chat_module(human_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
